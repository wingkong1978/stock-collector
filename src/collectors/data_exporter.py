#!/usr/bin/env python3
"""
Data Export Module
æ•°æ®å¯¼å‡ºæ¨¡å— - æ”¯æŒ Excel æ ¼å¼
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import pandas as pd
from datetime import datetime
from typing import Optional, List, Dict, Any
from pathlib import Path
from loguru import logger


class DataExporter:
    """æ•°æ®å¯¼å‡ºå™¨"""
    
    def __init__(self, config_path: str = "config"):
        self.config_path = Path(config_path)
        self.load_config()
        self.setup_storage()
    
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path / "stocks.json", "r", encoding="utf-8") as f:
                self.stocks_config = json.load(f)
            with open(self.config_path / "settings.json", "r", encoding="utf-8") as f:
                self.settings = json.load(f)
            logger.info("é…ç½®åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def setup_storage(self):
        """è®¾ç½®å­˜å‚¨ç›®å½•"""
        storage_path = Path(self.settings["storage"]["path"])
        self.raw_path = storage_path / "raw"
        self.processed_path = storage_path / "processed"
        self.news_path = storage_path / "news"
        self.export_path = storage_path / "exports"
        
        self.export_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"å¯¼å‡ºç›®å½•: {self.export_path}")
    
    def find_latest_files(self, pattern: str, directory: Path) -> List[Path]:
        """æŸ¥æ‰¾æœ€æ–°çš„æ–‡ä»¶"""
        files = list(directory.glob(pattern))
        if not files:
            return []
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
        files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        return files
    
    def export_stock_data(self, stock_code: Optional[str] = None, 
                         output_file: Optional[str] = None) -> Optional[Path]:
        """
        å¯¼å‡ºè‚¡ç¥¨è¡Œæƒ…æ•°æ®åˆ° Excel
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼ŒNone åˆ™å¯¼å‡ºæ‰€æœ‰
            output_file: è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            å¯¼å‡ºçš„æ–‡ä»¶è·¯å¾„
        """
        try:
            # æŸ¥æ‰¾è‚¡ç¥¨æ•°æ®æ–‡ä»¶
            pattern = "stocks_*.csv"
            
            files = self.find_latest_files(pattern, self.raw_path)
            
            if not files:
                logger.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨æ•°æ®æ–‡ä»¶")
                return None
            
            # è¯»å–æ‰€æœ‰æ•°æ®
            all_data = []
            for file in files[:10]:  # æœ€å¤šè¯»å–æœ€è¿‘10ä¸ªæ–‡ä»¶
                try:
                    df = pd.read_csv(file)
                    df['_source_file'] = file.name
                    all_data.append(df)
                except Exception as e:
                    logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file}: {e}")
                    continue
            
            if not all_data:
                logger.error("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
                return None
            
            # åˆå¹¶æ•°æ®
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            if not output_file:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                stock_suffix = f"_{stock_code}" if stock_code else ""
                output_file = f"stock_data{stock_suffix}_{timestamp}.xlsx"
            
            output_path = self.export_path / output_file
            
            # å¯¼å‡ºåˆ° Excel
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                combined_df.to_excel(writer, sheet_name='è‚¡ç¥¨è¡Œæƒ…', index=False)
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                stats = {
                    'æŒ‡æ ‡': ['æ•°æ®æ¡æ•°', 'è‚¡ç¥¨æ•°é‡', 'å¼€å§‹æ—¶é—´', 'ç»“æŸæ—¶é—´', 'æ•°æ®æ¥æº'],
                    'æ•°å€¼': [
                        len(combined_df),
                        combined_df['ä»£ç '].nunique() if 'ä»£ç ' in combined_df.columns else 0,
                        combined_df['collected_at'].min() if 'collected_at' in combined_df.columns else 'N/A',
                        combined_df['collected_at'].max() if 'collected_at' in combined_df.columns else 'N/A',
                        ', '.join(combined_df['_source'].unique()) if '_source' in combined_df.columns else 'N/A'
                    ]
                }
                stats_df = pd.DataFrame(stats)
                stats_df.to_excel(writer, sheet_name='ç»Ÿè®¡ä¿¡æ¯', index=False)
            
            logger.info(f"è‚¡ç¥¨æ•°æ®å·²å¯¼å‡º: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºè‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return None
    
    def export_news_data(self, stock_code: Optional[str] = None,
                        output_file: Optional[str] = None) -> Optional[Path]:
        """
        å¯¼å‡ºæ–°é—»æ•°æ®åˆ° Excel
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼ŒNone åˆ™å¯¼å‡ºæ‰€æœ‰
            output_file: è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            å¯¼å‡ºçš„æ–‡ä»¶è·¯å¾„
        """
        try:
            # æŸ¥æ‰¾æ–°é—»æ•°æ®æ–‡ä»¶
            if stock_code:
                pattern = f"news_{stock_code}_*.csv"
            else:
                pattern = "news_*.csv"
            
            files = self.find_latest_files(pattern, self.news_path)
            
            if not files:
                logger.warning(f"æœªæ‰¾åˆ°æ–°é—»æ•°æ®æ–‡ä»¶")
                return None
            
            # è¯»å–æ‰€æœ‰æ•°æ®
            all_data = []
            for file in files[:20]:  # æœ€å¤šè¯»å–æœ€è¿‘20ä¸ªæ–‡ä»¶
                try:
                    df = pd.read_csv(file)
                    df['_source_file'] = file.name
                    all_data.append(df)
                except Exception as e:
                    logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file}: {e}")
                    continue
            
            if not all_data:
                logger.error("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
                return None
            
            # åˆå¹¶æ•°æ®å¹¶å»é‡
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # æ ¹æ®æ–°é—»æ ‡é¢˜å»é‡
            if 'æ–°é—»æ ‡é¢˜' in combined_df.columns:
                combined_df = combined_df.drop_duplicates(subset=['æ–°é—»æ ‡é¢˜'], keep='first')
            
            # ç”Ÿæˆæ–‡ä»¶å
            if not output_file:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                stock_suffix = f"_{stock_code}" if stock_code else ""
                output_file = f"news_data{stock_suffix}_{timestamp}.xlsx"
            
            output_path = self.export_path / output_file
            
            # å¯¼å‡ºåˆ° Excel
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # ä¸»è¦æ–°é—»æ•°æ®
                combined_df.to_excel(writer, sheet_name='æ–°é—»æ•°æ®', index=False)
                
                # ç»Ÿè®¡ä¿¡æ¯
                stats = {
                    'æŒ‡æ ‡': ['æ–°é—»æ¡æ•°', 'æ¶‰åŠè‚¡ç¥¨', 'æ¥æºæ•°é‡', 'æ—¶é—´èŒƒå›´'],
                    'æ•°å€¼': [
                        len(combined_df),
                        combined_df['_stock_code'].nunique() if '_stock_code' in combined_df.columns else 0,
                        combined_df['æ–‡ç« æ¥æº'].nunique() if 'æ–‡ç« æ¥æº' in combined_df.columns else 0,
                        f"{combined_df['å‘å¸ƒæ—¶é—´'].min()} ~ {combined_df['å‘å¸ƒæ—¶é—´'].max()}" 
                        if 'å‘å¸ƒæ—¶é—´' in combined_df.columns else 'N/A'
                    ]
                }
                stats_df = pd.DataFrame(stats)
                stats_df.to_excel(writer, sheet_name='ç»Ÿè®¡ä¿¡æ¯', index=False)
                
                # æ¥æºç»Ÿè®¡
                if 'æ–‡ç« æ¥æº' in combined_df.columns:
                    source_stats = combined_df['æ–‡ç« æ¥æº'].value_counts().reset_index()
                    source_stats.columns = ['æ¥æº', 'æ•°é‡']
                    source_stats.to_excel(writer, sheet_name='æ¥æºç»Ÿè®¡', index=False)
            
            logger.info(f"æ–°é—»æ•°æ®å·²å¯¼å‡º: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºæ–°é—»æ•°æ®å¤±è´¥: {e}")
            return None
    
    def export_all(self, stock_code: Optional[str] = None) -> Dict[str, Optional[Path]]:
        """
        å¯¼å‡ºæ‰€æœ‰æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            å¯¼å‡ºçš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        logger.info("å¼€å§‹å¯¼å‡ºæ‰€æœ‰æ•°æ®...")
        
        results = {
            'stock_data': self.export_stock_data(stock_code),
            'news_data': self.export_news_data(stock_code)
        }
        
        # æ±‡æ€»ä¿¡æ¯
        success_count = sum(1 for v in results.values() if v is not None)
        logger.info(f"å¯¼å‡ºå®Œæˆ: {success_count}/2 æˆåŠŸ")
        
        return results
    
    def list_exports(self) -> List[Path]:
        """åˆ—å‡ºæ‰€æœ‰å¯¼å‡ºæ–‡ä»¶"""
        files = list(self.export_path.glob("*.xlsx"))
        files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        return files


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ•°æ®å¯¼å‡ºå·¥å…·")
    parser.add_argument("--stock", type=str, help="è‚¡ç¥¨ä»£ç ")
    parser.add_argument("--type", type=str, choices=['stock', 'news', 'all'], 
                       default='all', help="å¯¼å‡ºç±»å‹")
    parser.add_argument("--output", type=str, help="è¾“å‡ºæ–‡ä»¶å")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯¼å‡ºæ–‡ä»¶")
    
    args = parser.parse_args()
    
    exporter = DataExporter()
    
    if args.list:
        exports = exporter.list_exports()
        print(f"\nğŸ“ å¯¼å‡ºæ–‡ä»¶åˆ—è¡¨ ({len(exports)} ä¸ª):")
        for i, file in enumerate(exports[:10], 1):
            size = file.stat().st_size / 1024
            print(f"  {i}. {file.name} ({size:.1f} KB)")
        return
    
    if args.type == 'stock':
        result = exporter.export_stock_data(args.stock, args.output)
        if result:
            print(f"\nâœ… è‚¡ç¥¨æ•°æ®å·²å¯¼å‡º: {result}")
        else:
            print("\nâŒ å¯¼å‡ºå¤±è´¥")
    
    elif args.type == 'news':
        result = exporter.export_news_data(args.stock, args.output)
        if result:
            print(f"\nâœ… æ–°é—»æ•°æ®å·²å¯¼å‡º: {result}")
        else:
            print("\nâŒ å¯¼å‡ºå¤±è´¥")
    
    else:  # all
        results = exporter.export_all(args.stock)
        print("\nğŸ“Š å¯¼å‡ºç»“æœ:")
        for key, path in results.items():
            if path:
                print(f"  âœ… {key}: {path}")
            else:
                print(f"  âŒ {key}: å¯¼å‡ºå¤±è´¥")


if __name__ == "__main__":
    main()
